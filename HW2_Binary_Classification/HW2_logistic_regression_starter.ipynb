{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a3af80b",
   "metadata": {},
   "source": [
    "# TP noté 2 – Évaluation des classificateurs binaires et régression logistique (HW2)\n",
    "## Notebook starter (hybride) — à compléter en groupe\n",
    "\n",
    "### Organisation attendue\n",
    "Ce notebook suppose l’arborescence suivante (après décompression de l’archive fournie par l’enseignant) :\n",
    "\n",
    "```\n",
    "HW2_Binary_Classification/\n",
    "├── data/\n",
    "│   ├── x_train.csv\n",
    "│   ├── y_train.csv\n",
    "│   ├── x_valid.csv\n",
    "│   ├── y_valid.csv\n",
    "│   ├── x_test.csv\n",
    "│   └── y_test.csv\n",
    "├── HW2_logistic_regression.ipynb   ← ce notebook\n",
    "```\n",
    "\n",
    "### Important – Nature de l’évaluation\n",
    "L’évaluation porte prioritairement sur la compréhension, la capacité à expliquer, justifier, défendre vos choix, et à adapter votre raisonnement.\n",
    "Un code fonctionnel sans compréhension démontrée ne garantit pas une bonne note.\n",
    "\n",
    "### Règles de travail\n",
    "- Complétez uniquement les cellules marquées TODO.\n",
    "- N’effacez pas les cellules de test/figure.\n",
    "- Les réponses aux questions se font dans le rapport PDF (sans code), mais vous trouverez ici des rappels en Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a54b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ada85c",
   "metadata": {},
   "source": [
    "## 0) Chargement des données (NE PAS MODIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b14869",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "x_train = pd.read_csv(f\"{DATA_DIR}/x_train.csv\")\n",
    "y_train = pd.read_csv(f\"{DATA_DIR}/y_train.csv\")\n",
    "\n",
    "x_valid = pd.read_csv(f\"{DATA_DIR}/x_valid.csv\")\n",
    "y_valid = pd.read_csv(f\"{DATA_DIR}/y_valid.csv\")\n",
    "\n",
    "x_test = pd.read_csv(f\"{DATA_DIR}/x_test.csv\")\n",
    "y_test = pd.read_csv(f\"{DATA_DIR}/y_test.csv\")\n",
    "\n",
    "# y_* peut être une colonne unique ; on convertit en vecteur 1D\n",
    "def _to_1d(y_df):\n",
    "    if isinstance(y_df, pd.DataFrame):\n",
    "        if y_df.shape[1] != 1:\n",
    "            raise ValueError(\"y should have exactly one column\")\n",
    "        return y_df.iloc[:, 0].astype(int).values\n",
    "    return np.asarray(y_df).astype(int).reshape(-1)\n",
    "\n",
    "ytr = _to_1d(y_train)\n",
    "yva = _to_1d(y_valid)\n",
    "yte = _to_1d(y_test)\n",
    "\n",
    "print(\"x_train:\", x_train.shape, \"y_train:\", ytr.shape)\n",
    "print(\"x_valid:\", x_valid.shape, \"y_valid:\", yva.shape)\n",
    "print(\"x_test :\", x_test.shape,  \"y_test :\", yte.shape)\n",
    "\n",
    "display(x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d58ff4",
   "metadata": {},
   "source": [
    "## A2) Table A1 (Rapport) — descriptif des ensembles\n",
    "À produire dans le rapport PDF : pour train/valid/test\n",
    "- total count\n",
    "- positive label count\n",
    "- fraction positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (optionnel) : construisez ici votre Table A1 pour faciliter le copier-coller dans le rapport.\n",
    "# Indication : utilisez len(y), y.sum(), y.mean()\n",
    "\n",
    "def summarize_split(y):\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return {\n",
    "        \"total_count\": int(len(y)),\n",
    "        \"positive_count\": int(y.sum()),\n",
    "        \"fraction_positive\": float(y.mean())\n",
    "    }\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"train\": summarize_split(ytr),\n",
    "    \"valid\": summarize_split(yva),\n",
    "    \"test\":  summarize_split(yte),\n",
    "})\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb664c5",
   "metadata": {},
   "source": [
    "# Bloc A — Métriques pour prédictions binaires (NumPy)\n",
    "\n",
    "Vous devez implémenter les fonctions suivantes from scratch.\n",
    "Elles seront ensuite utilisées dans les analyses (baseline, choix de seuil, matrices de confusion).\n",
    "\n",
    "Rappel : y_true et y_pred sont des vecteurs de 0/1 de même taille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ca89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# TODO A1(a): TP, TN, FP, FN\n",
    "# =========================\n",
    "def calc_TP_TN_FP_FN(y_true, y_pred):\n",
    "    '''\n",
    "    Return (TP, TN, FP, FN) as integers.\n",
    "    Convention:\n",
    "    - Positive class = 1 (cancer)\n",
    "    - Negative class = 0 (no cancer)\n",
    "    '''\n",
    "    # TODO: implement\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TODO A1(b): Accuracy\n",
    "# =========================\n",
    "def calc_ACC(y_true, y_pred):\n",
    "    '''Return accuracy in [0,1].'''\n",
    "    # TODO: implement\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TODO A1(c): TPR (Sensitivity) and TNR (Specificity)\n",
    "# =========================\n",
    "def calc_TPR(y_true, y_pred):\n",
    "    '''TPR = TP / (TP + FN). If denominator is 0, return np.nan.'''\n",
    "    # TODO: implement\n",
    "    raise NotImplementedError\n",
    "\n",
    "def calc_TNR(y_true, y_pred):\n",
    "    '''TNR = TN / (TN + FP). If denominator is 0, return np.nan.'''\n",
    "    # TODO: implement\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TODO A1(d): PPV and NPV\n",
    "# =========================\n",
    "def calc_PPV(y_true, y_pred):\n",
    "    '''PPV = TP / (TP + FP). If denominator is 0, return np.nan.'''\n",
    "    # TODO: implement\n",
    "    raise NotImplementedError\n",
    "\n",
    "def calc_NPV(y_true, y_pred):\n",
    "    '''NPV = TN / (TN + FN). If denominator is 0, return np.nan.'''\n",
    "    # TODO: implement\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac708bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests unitaires rapides (NE PAS MODIFIER)\n",
    "yt = np.array([1,1,0,0,1,0])\n",
    "yp = np.array([1,0,0,0,1,1])\n",
    "\n",
    "TP, TN, FP, FN = calc_TP_TN_FP_FN(yt, yp)\n",
    "print(\"TP,TN,FP,FN =\", TP, TN, FP, FN)\n",
    "\n",
    "print(\"ACC =\", calc_ACC(yt, yp))\n",
    "print(\"TPR =\", calc_TPR(yt, yp))\n",
    "print(\"TNR =\", calc_TNR(yt, yp))\n",
    "print(\"PPV =\", calc_PPV(yt, yp))\n",
    "print(\"NPV =\", calc_NPV(yt, yp))\n",
    "\n",
    "# Vérifications attendues: TP=2, TN=2, FP=1, FN=1\n",
    "assert (TP, TN, FP, FN) == (2, 2, 1, 1)\n",
    "assert abs(calc_ACC(yt, yp) - (4/6)) < 1e-12\n",
    "assert abs(calc_TPR(yt, yp) - (2/3)) < 1e-12\n",
    "assert abs(calc_TNR(yt, yp) - (2/3)) < 1e-12\n",
    "assert abs(calc_PPV(yt, yp) - (2/3)) < 1e-12\n",
    "assert abs(calc_NPV(yt, yp) - (2/3)) < 1e-12\n",
    "\n",
    "print(\"OK: tests métriques binaires\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78afec8f",
   "metadata": {},
   "source": [
    "# Bloc B — Baseline \"predict-0-always\" et coûts des erreurs\n",
    "\n",
    "À faire dans le notebook : matrice de confusion + métriques sur le jeu de test.\n",
    "À discuter dans le rapport : pourquoi l’accuracy peut être trompeuse, coûts FP vs FN, métriques prioritaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_2x2(y_true, y_pred):\n",
    "    '''\n",
    "    Return a 2x2 numpy array with orientation:\n",
    "    rows = true class (0 then 1)\n",
    "    cols = predicted class (0 then 1)\n",
    "\n",
    "    [[TN, FP],\n",
    "     [FN, TP]]\n",
    "    '''\n",
    "    TP, TN, FP, FN = calc_TP_TN_FP_FN(y_true, y_pred)\n",
    "    return np.array([[TN, FP],\n",
    "                     [FN, TP]], dtype=int)\n",
    "\n",
    "# Baseline: always predict 0\n",
    "y_pred0_test = np.zeros_like(yte, dtype=int)\n",
    "\n",
    "cm0 = confusion_matrix_2x2(yte, y_pred0_test)\n",
    "acc0 = calc_ACC(yte, y_pred0_test)\n",
    "tpr0 = calc_TPR(yte, y_pred0_test)\n",
    "ppv0 = calc_PPV(yte, y_pred0_test)\n",
    "\n",
    "cm0, acc0, tpr0, ppv0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac790f1",
   "metadata": {},
   "source": [
    "Questions (Rapport PDF) — Bloc B\n",
    "1. Quelle accuracy obtient la baseline sur le test ? Est-ce un bon classificateur en pratique ?\n",
    "2. Décrivez les erreurs possibles (FP/FN) en termes cliniques et leurs coûts.\n",
    "3. Quelles métriques doivent être prioritaires pour cette application ? Justifiez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf775d",
   "metadata": {},
   "source": [
    "# Bloc C — Régression logistique (sklearn) + sélection de C (validation)\n",
    "\n",
    "Vous allez entraîner 2 modèles :\n",
    "- F=2 : age, famhistory\n",
    "- F=3 : marker, age, famhistory\n",
    "\n",
    "Vous choisirez C en minimisant la log-loss sur validation, en explorant:\n",
    "C_grid = np.logspace(-9, 6, 31)\n",
    "\n",
    "Important : normalisez les features via StandardScaler (Pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14aa0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes (NE PAS MODIFIER)\n",
    "cols_F2 = [\"age\", \"famhistory\"]\n",
    "cols_F3 = [\"marker\", \"age\", \"famhistory\"]\n",
    "\n",
    "Xtr_F2 = x_train[cols_F2].values\n",
    "Xva_F2 = x_valid[cols_F2].values\n",
    "Xte_F2 = x_test[cols_F2].values\n",
    "\n",
    "Xtr_F3 = x_train[cols_F3].values\n",
    "Xva_F3 = x_valid[cols_F3].values\n",
    "Xte_F3 = x_test[cols_F3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bb63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid = np.logspace(-9, 6, 31)\n",
    "\n",
    "def fit_lr_select_C_by_valid_logloss(Xtr, ytr, Xva, yva, C_grid, random_state=0):\n",
    "    '''\n",
    "    Train LR models across C_grid and return:\n",
    "    - best_model (Pipeline)\n",
    "    - best_C\n",
    "    - table (DataFrame) with columns: C, train_logloss, valid_logloss\n",
    "    '''\n",
    "    rows = []\n",
    "    best_C = None\n",
    "    best_valid = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for C in C_grid:\n",
    "        model = Pipeline(steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"lr\", LogisticRegression(\n",
    "                solver=\"lbfgs\",\n",
    "                penalty=\"l2\",\n",
    "                C=float(C),\n",
    "                max_iter=5000,\n",
    "                random_state=random_state\n",
    "            ))\n",
    "        ])\n",
    "        model.fit(Xtr, ytr)\n",
    "\n",
    "        ptr = model.predict_proba(Xtr)[:, 1]\n",
    "        pva = model.predict_proba(Xva)[:, 1]\n",
    "\n",
    "        tr_ll = log_loss(ytr, ptr, labels=[0,1])\n",
    "        va_ll = log_loss(yva, pva, labels=[0,1])\n",
    "\n",
    "        rows.append({\"C\": float(C), \"train_logloss\": tr_ll, \"valid_logloss\": va_ll})\n",
    "\n",
    "        if va_ll < best_valid:\n",
    "            best_valid = va_ll\n",
    "            best_C = float(C)\n",
    "            best_model = model\n",
    "\n",
    "    table = pd.DataFrame(rows)\n",
    "    return best_model, best_C, table\n",
    "\n",
    "# Entraînez et sélectionnez C pour F=2 puis F=3\n",
    "best_F2_model, best_C_F2, table_F2 = fit_lr_select_C_by_valid_logloss(Xtr_F2, ytr, Xva_F2, yva, C_grid, random_state=0)\n",
    "best_F3_model, best_C_F3, table_F3 = fit_lr_select_C_by_valid_logloss(Xtr_F3, ytr, Xva_F3, yva, C_grid, random_state=0)\n",
    "\n",
    "best_C_F2, best_C_F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96151793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation (optionnelle) : log-loss vs C\n",
    "plt.figure()\n",
    "plt.semilogx(table_F2[\"C\"], table_F2[\"valid_logloss\"], label=\"F=2 valid logloss\")\n",
    "plt.semilogx(table_F3[\"C\"], table_F3[\"valid_logloss\"], label=\"F=3 valid logloss\")\n",
    "plt.xlabel(\"C (log scale)\")\n",
    "plt.ylabel(\"Validation log-loss\")\n",
    "plt.title(\"Sélection de C (validation)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b30dd8",
   "metadata": {},
   "source": [
    "## C2) ROC sur le jeu de validation — Figure C1 (obligatoire)\n",
    "\n",
    "Tracer une figure unique contenant 2 courbes ROC (validation) :\n",
    "- modèle F=2 (bleu, style '.-')\n",
    "- modèle F=3 (rouge, style '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c550620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilités sur validation\n",
    "pva_F2 = best_F2_model.predict_proba(Xva_F2)[:, 1]\n",
    "pva_F3 = best_F3_model.predict_proba(Xva_F3)[:, 1]\n",
    "\n",
    "fpr2, tpr2, _ = roc_curve(yva, pva_F2)\n",
    "fpr3, tpr3, _ = roc_curve(yva, pva_F3)\n",
    "\n",
    "auc2 = roc_auc_score(yva, pva_F2)\n",
    "auc3 = roc_auc_score(yva, pva_F3)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr2, tpr2, \"b.-\", label=f\"F=2 (AUC={auc2:.3f})\")\n",
    "plt.plot(fpr3, tpr3, \"r.-\", label=f\"F=3 (AUC={auc3:.3f})\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"Figure C1 — ROC (validation)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "print(\"best_C_F2:\", best_C_F2, \"best_C_F3:\", best_C_F3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ba68f",
   "metadata": {},
   "source": [
    "# Bloc D — Sélection du seuil de décision (modèle F=3)\n",
    "\n",
    "Comparer 3 stratégies (sur le test) :\n",
    "1. seuil fixe 0.5\n",
    "2. seuil choisi sur validation : maximiser TPR sous contrainte PPV ≥ 0.98\n",
    "3. seuil choisi sur validation : maximiser PPV sous contrainte TPR ≥ 0.98\n",
    "\n",
    "Important : seuil choisi sur validation puis évalué sur test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8866b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers (NE PAS MODIFIER)\n",
    "def predict_from_threshold(probas, threshold):\n",
    "    return (np.asarray(probas) >= float(threshold)).astype(int)\n",
    "\n",
    "def compute_perf_metrics_across_thresholds(y_true, probas, thresholds):\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        y_pred = predict_from_threshold(probas, t)\n",
    "        TP, TN, FP, FN = calc_TP_TN_FP_FN(y_true, y_pred)\n",
    "        rows.append({\n",
    "            \"threshold\": float(t),\n",
    "            \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "            \"ACC\": calc_ACC(y_true, y_pred),\n",
    "            \"TPR\": calc_TPR(y_true, y_pred),\n",
    "            \"TNR\": calc_TNR(y_true, y_pred),\n",
    "            \"PPV\": calc_PPV(y_true, y_pred),\n",
    "            \"NPV\": calc_NPV(y_true, y_pred),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def candidate_thresholds_from_probas(probas, n=200):\n",
    "    p = np.asarray(probas).reshape(-1)\n",
    "    lo, hi = float(np.min(p)), float(np.max(p))\n",
    "    grid = np.linspace(lo, hi, int(n))\n",
    "    extra = np.array([0.0, 0.5, 1.0, lo, hi])\n",
    "    thr = np.unique(np.clip(np.concatenate([grid, extra]), 0.0, 1.0))\n",
    "    return thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a96f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilités F=3 sur validation et test\n",
    "pva = best_F3_model.predict_proba(Xva_F3)[:, 1]\n",
    "pte = best_F3_model.predict_proba(Xte_F3)[:, 1]\n",
    "\n",
    "thresholds = candidate_thresholds_from_probas(pva, n=400)\n",
    "metrics_va = compute_perf_metrics_across_thresholds(yva, pva, thresholds)\n",
    "\n",
    "metrics_va.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15209c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO D1: sélectionner 2 seuils sur validation\n",
    "# Stratégie 2: maximiser TPR sous contrainte PPV >= 0.98\n",
    "# Stratégie 3: maximiser PPV sous contrainte TPR >= 0.98\n",
    "\n",
    "# Résultat attendu: définir deux scalaires float:\n",
    "# - thr_best_TPR_under_PPV\n",
    "# - thr_best_PPV_under_TPR\n",
    "\n",
    "# --- TODO: implement selection logic ---\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation sur test (NE PAS MODIFIER, dépend de vos seuils)\n",
    "thr_05 = 0.5\n",
    "yhat_05 = predict_from_threshold(pte, thr_05)\n",
    "\n",
    "yhat_TPR = predict_from_threshold(pte, thr_best_TPR_under_PPV)\n",
    "yhat_PPV = predict_from_threshold(pte, thr_best_PPV_under_TPR)\n",
    "\n",
    "cms = [\n",
    "    confusion_matrix_2x2(yte, yhat_05),\n",
    "    confusion_matrix_2x2(yte, yhat_TPR),\n",
    "    confusion_matrix_2x2(yte, yhat_PPV),\n",
    "]\n",
    "\n",
    "tprs = [calc_TPR(yte, yhat_05), calc_TPR(yte, yhat_TPR), calc_TPR(yte, yhat_PPV)]\n",
    "ppvs = [calc_PPV(yte, yhat_05), calc_PPV(yte, yhat_TPR), calc_PPV(yte, yhat_PPV)]\n",
    "\n",
    "cms, tprs, ppvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure D1 — matrices de confusion + (TPR, PPV) sur test (OBLIGATOIRE)\n",
    "titles = [\n",
    "    \"F=3 LR — thr=0.5\",\n",
    "    f\"F=3 LR — thr(TPR max | PPV>=0.98) = {thr_best_TPR_under_PPV:.3f}\",\n",
    "    f\"F=3 LR — thr(PPV max | TPR>=0.98) = {thr_best_PPV_under_TPR:.3f}\",\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for j in range(3):\n",
    "    ax = plt.subplot(2, 3, j+1)\n",
    "    ax.imshow(cms[j], cmap=\"Blues\")\n",
    "    ax.set_title(titles[j])\n",
    "    ax.set_xticks([0, 1]); ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels([\"pred 0\", \"pred 1\"])\n",
    "    ax.set_yticklabels([\"true 0\", \"true 1\"])\n",
    "    for (i, k), val in np.ndenumerate(cms[j]):\n",
    "        ax.text(k, i, str(val), ha=\"center\", va=\"center\", color=\"black\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "\n",
    "    ax2 = plt.subplot(2, 3, j+4)\n",
    "    ax2.bar([0, 1], [tprs[j], ppvs[j]])\n",
    "    ax2.set_xticks([0, 1])\n",
    "    ax2.set_xticklabels([\"TPR\", \"PPV\"])\n",
    "    ax2.set_ylim([0, 1.05])\n",
    "    ax2.set_title(\"Test metrics\")\n",
    "    for idx, v in enumerate([tprs[j], ppvs[j]]):\n",
    "        ax2.text(idx, min(1.02, v + 0.03), f\"{v:.3f}\", ha=\"center\")\n",
    "\n",
    "plt.suptitle(\"Figure D1 — Performance test (confusion matrices, TPR & PPV)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7679cdd",
   "metadata": {},
   "source": [
    "Questions (Rapport PDF) — Bloc D\n",
    "1. Comparez les 3 matrices de confusion. Quelle stratégie respecte le mieux la priorité clinique (éviter FN à tout prix) tout en réduisant les biopsies inutiles ?\n",
    "2. En supposant que la pratique actuelle est de biopsier tout le monde : combien de biopsies inutiles sont évitées sur le test ? Quel pourcentage de biopsies actuelles cela représente ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158359b",
   "metadata": {},
   "source": [
    "# Bloc E — Perte logistique et stabilité numérique (NumPy)\n",
    "\n",
    "Implémenter :\n",
    "- BCE moyenne à partir de probabilités (avec clipping 1e-14)\n",
    "- logsumexp stable (base e)\n",
    "- BCE moyenne à partir de scores (avec conversion base 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03297413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO E(a): mean BCE from probas (base-2 logs)\n",
    "def calc_mean_binary_cross_entropy_from_probas(y_true, p_pred, eps=1e-14):\n",
    "    '''\n",
    "    y_true: array of 0/1\n",
    "    p_pred: array of probabilities in (0,1)\n",
    "    Must clip: eps <= p <= 1-eps\n",
    "    BCE(y,p) = - y log2(p) - (1-y) log2(1-p)\n",
    "    Return mean over samples.\n",
    "    '''\n",
    "    # TODO: implement\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# TODO E(b): my_logsumexp (natural log base-e)\n",
    "def my_logsumexp(a):\n",
    "    '''\n",
    "    a: 1D array-like of floats.\n",
    "    Return log(sum(exp(a))) computed stably, using the logsumexp trick.\n",
    "    Natural log (np.log).\n",
    "    '''\n",
    "    # TODO: implement\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# TODO E(c): mean BCE from scores via logsumexp\n",
    "def calc_mean_binary_cross_entropy_from_scores(y_true, s_pred):\n",
    "    '''\n",
    "    y_true: 0/1\n",
    "    s_pred: real-valued scores in (-inf, inf)\n",
    "\n",
    "    scoreBCE(y,s) = log2(1 + exp(-s)) if y=1\n",
    "                  = log2(1 + exp( s)) if y=0\n",
    "    Use: log2(1+exp(flip(y)*s)) = logsumexp([0, flip(y)*s]) / log(2)\n",
    "\n",
    "    flip(y)= -1 if y=1 else +1\n",
    "    Use my_logsumexp (base-e) and convert to base-2.\n",
    "    '''\n",
    "    # TODO: implement\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests numériques (NE PAS MODIFIER)\n",
    "yt = np.array([1, 0, 1, 0], dtype=int)\n",
    "p  = np.array([0.9, 0.1, 0.8, 0.2], dtype=float)\n",
    "\n",
    "eps = 1e-14\n",
    "pc = np.clip(p, eps, 1-eps)\n",
    "bce_direct = np.mean(-yt*np.log2(pc) - (1-yt)*np.log2(1-pc))\n",
    "\n",
    "bce_fn = calc_mean_binary_cross_entropy_from_probas(yt, p)\n",
    "print(\"BCE probas direct:\", bce_direct, \"BCE probas fn:\", bce_fn)\n",
    "assert abs(bce_direct - bce_fn) < 1e-10\n",
    "\n",
    "lse = my_logsumexp(np.array([1000.0, -999.0]))\n",
    "print(\"logsumexp([1000,-999]) =\", lse)\n",
    "assert abs(lse - 1000.0) < 1e-6\n",
    "\n",
    "s = np.array([2.0, -2.0, 1.0, -1.0])\n",
    "sig = 1.0/(1.0 + np.exp(-s))\n",
    "bce_p = calc_mean_binary_cross_entropy_from_probas(yt, sig)\n",
    "bce_s = calc_mean_binary_cross_entropy_from_scores(yt, s)\n",
    "\n",
    "print(\"BCE probas(sigmoid(scores)):\", bce_p)\n",
    "print(\"BCE scores:\", bce_s)\n",
    "assert abs(bce_p - bce_s) < 1e-8\n",
    "\n",
    "print(\"OK: tests stabilité numérique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e187e02",
   "metadata": {},
   "source": [
    "# À rendre\n",
    "1. Notebook .ipynb complété (Figures C1 et D1 obligatoires).\n",
    "2. Rapport PDF (≤ 6 pages), sans code, avec références explicites à vos figures/valeurs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
